{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd20e214",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1002)>\n"
     ]
    }
   ],
   "source": [
    "import docx2txt\n",
    "import spacy\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa46174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=\"\"\n",
    "with open(\"test.txt\") as file:\n",
    "    data=file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5b6d55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=\"\"\n",
    "with open(\"doc2.txt\") as file:\n",
    "    data2=file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc067180",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp  = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5562635",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1=nlp(data)\n",
    "d2=nlp(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f854b3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d057c909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiger----->PROPN\n",
      "is----->AUX\n",
      "a----->DET\n",
      "very----->ADV\n",
      "violent----->ADJ\n",
      "wild----->ADJ\n",
      "animal----->NOUN\n",
      ".----->PUNCT\n",
      "It----->PRON\n",
      "has----->AUX\n",
      "been----->AUX\n",
      "declared----->VERB\n",
      "by----->ADP\n",
      "the----->DET\n",
      "Indian----->ADJ\n",
      "government----->NOUN\n",
      "as----->ADP\n",
      "the----->DET\n",
      "national----->ADJ\n",
      "animal----->NOUN\n",
      "of----->ADP\n",
      "India----->PROPN\n",
      ".----->PUNCT\n",
      "It----->PRON\n",
      "is----->AUX\n",
      "considered----->VERB\n",
      "as----->ADP\n",
      "the----->DET\n",
      "strongest----->ADJ\n",
      ",----->PUNCT\n",
      "powerful----->ADJ\n",
      "and----->CCONJ\n",
      "most----->ADV\n",
      "beautiful----->ADJ\n",
      "animal----->NOUN\n",
      "on----->ADP\n",
      "this----->DET\n",
      "planet----->NOUN\n",
      ".----->PUNCT\n",
      "It----->PRON\n",
      "lives----->VERB\n",
      "in----->ADP\n",
      "a----->DET\n",
      "dense----->ADJ\n",
      "forest----->NOUN\n",
      "however----->ADV\n",
      "sometimes----->ADV\n",
      "comes----->VERB\n",
      "to----->ADP\n",
      "the----->DET\n",
      "villages----->NOUN\n",
      "and----->CCONJ\n",
      "other----->ADJ\n",
      "residential----->ADJ\n",
      "places----->NOUN\n",
      "in----->ADP\n",
      "the----->DET\n",
      "search----->NOUN\n",
      "of----->ADP\n",
      "food----->NOUN\n",
      "or----->CCONJ\n",
      "deforestation----->NOUN\n",
      ".----->PUNCT\n",
      "Siberian----->PROPN\n",
      "Tigers----->PROPN\n",
      "are----->AUX\n",
      "generally----->ADV\n",
      "used----->VERB\n",
      "to----->PART\n",
      "live----->VERB\n",
      "in----->ADP\n",
      "cold----->ADJ\n",
      "places----->NOUN\n",
      "however----->ADV\n",
      "Royal----->PROPN\n",
      "Bengal----->PROPN\n",
      "Tigers----->PROPN\n",
      "in----->ADP\n",
      "the----->DET\n",
      "forest----->NOUN\n",
      "near----->ADP\n",
      "river----->NOUN\n",
      "that----->PRON\n",
      "’s----->VERB\n",
      "why----->SCONJ\n",
      "they----->PRON\n",
      "know----->VERB\n",
      "well----->ADV\n",
      "to----->PART\n",
      "swim----->VERB\n",
      ".----->PUNCT\n",
      "\n",
      "\n",
      "----->SPACE\n",
      "Few----->ADJ\n",
      "decades----->NOUN\n",
      "ago----->ADV\n",
      ",----->PUNCT\n",
      "tigers----->NOUN\n",
      "were----->AUX\n",
      "hunted----->VERB\n",
      "by----->ADP\n",
      "the----->DET\n",
      "people----->NOUN\n",
      "to----->ADP\n",
      "a----->DET\n",
      "great----->ADJ\n",
      "extent----->NOUN\n",
      "for----->ADP\n",
      "fulfilling----->VERB\n",
      "various----->ADJ\n",
      "purposes----->NOUN\n",
      "including----->VERB\n",
      "illegal----->ADJ\n",
      "business----->NOUN\n",
      "of----->ADP\n",
      "its----->PRON\n",
      "body----->NOUN\n",
      "parts----->NOUN\n",
      "like----->ADP\n",
      "skin----->NOUN\n",
      ",----->PUNCT\n",
      "bones----->NOUN\n",
      ",----->PUNCT\n",
      "teeth----->NOUN\n",
      ",----->PUNCT\n",
      "nail----->NOUN\n",
      ",----->PUNCT\n",
      "etc----->X\n",
      ".----->PUNCT\n",
      "It----->PRON\n",
      "resulted----->VERB\n",
      "in----->ADP\n",
      "the----->DET\n",
      "massive----->ADJ\n",
      "decrease----->NOUN\n",
      "in----->ADP\n",
      "the----->DET\n",
      "population----->NOUN\n",
      "of----->ADP\n",
      "tigers----->NOUN\n",
      "all----->ADV\n",
      "over----->ADP\n",
      "India----->PROPN\n",
      ".----->PUNCT\n",
      "Tigers----->NOUN\n",
      "are----->AUX\n",
      "also----->ADV\n",
      "found----->VERB\n",
      "in----->ADP\n",
      "other----->ADJ\n",
      "countries----->NOUN\n",
      "like----->ADP\n",
      "Bangladesh----->PROPN\n",
      ",----->PUNCT\n",
      "Cambodia----->PROPN\n",
      ",----->PUNCT\n",
      "Thailand----->PROPN\n",
      ",----->PUNCT\n",
      "Laos----->PROPN\n",
      ",----->PUNCT\n",
      "China----->PROPN\n",
      ",----->PUNCT\n",
      "Indonesia----->PROPN\n",
      ",----->PUNCT\n",
      "Myanmar----->PROPN\n",
      ",----->PUNCT\n",
      "Nepal----->PROPN\n",
      ",----->PUNCT\n",
      "Malaysia----->PROPN\n",
      ",----->PUNCT\n",
      "Russia----->PROPN\n",
      ",----->PUNCT\n",
      "Vietnam----->PROPN\n",
      ",----->PUNCT\n",
      "Bhutan----->PROPN\n",
      ",----->PUNCT\n",
      "etc----->X\n",
      ".----->PUNCT\n"
     ]
    }
   ],
   "source": [
    "for word in d1:\n",
    "    print(f\"{word.text}----->{word.pos_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8e6e1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ions----->NOUN\n",
      "belong----->VERB\n",
      "to----->ADP\n",
      "the----->DET\n",
      "Felidae----->PROPN\n",
      "family----->NOUN\n",
      ",----->PUNCT\n",
      "a----->DET\n",
      "cat----->NOUN\n",
      "family----->NOUN\n",
      "known----->VERB\n",
      "as----->ADP\n",
      "the----->DET\n",
      "giant----->ADJ\n",
      "cats----->NOUN\n",
      ".----->PUNCT\n",
      "The----->DET\n",
      "cat----->NOUN\n",
      "family----->NOUN\n",
      "comprises----->VERB\n",
      "lions----->NOUN\n",
      ",----->PUNCT\n",
      "tigers----->NOUN\n",
      ",----->PUNCT\n",
      "leopards----->NOUN\n",
      ",----->PUNCT\n",
      "panthers----->NOUN\n",
      ",----->PUNCT\n",
      "and----->CCONJ\n",
      "jaguars----->NOUN\n",
      ",----->PUNCT\n",
      "but----->CCONJ\n",
      "the----->DET\n",
      "lions----->NOUN\n",
      "are----->AUX\n",
      "considered----->VERB\n",
      "the----->DET\n",
      "most----->ADV\n",
      "powerful----->ADJ\n",
      ".----->PUNCT\n",
      "The----->DET\n",
      "lion----->NOUN\n",
      "is----->AUX\n",
      "regarded----->VERB\n",
      "as----->ADP\n",
      "one----->NUM\n",
      "of----->ADP\n",
      "the----->DET\n",
      "bravest----->ADJ\n",
      "animals----->NOUN\n",
      "and----->CCONJ\n",
      "looks----->VERB\n",
      "hefty----->ADJ\n",
      ".----->PUNCT\n",
      "They----->PRON\n",
      "are----->AUX\n",
      "also----->ADV\n",
      "called----->VERB\n",
      "the----->DET\n",
      "king----->NOUN\n",
      "of----->ADP\n",
      "the----->DET\n",
      "jungle----->NOUN\n",
      ".----->PUNCT\n",
      "Male----->ADJ\n",
      "lions----->NOUN\n",
      "have----->VERB\n",
      "a----->DET\n",
      "mane----->NOUN\n",
      "that----->PRON\n",
      "gives----->VERB\n",
      "them----->PRON\n",
      "a----->DET\n",
      "bulky----->ADJ\n",
      "appearance----->NOUN\n",
      ",----->PUNCT\n",
      "but----->CCONJ\n",
      "the----->DET\n",
      "mane----->NOUN\n",
      "is----->AUX\n",
      "absent----->ADJ\n",
      "in----->ADP\n",
      "female----->ADJ\n",
      "lions----->NOUN\n",
      ".----->PUNCT\n",
      "Lions----->NOUN\n",
      "live----->VERB\n",
      "in----->ADP\n",
      "groups----->NOUN\n",
      "called----->VERB\n",
      "‘----->PUNCT\n",
      "pride----->NOUN\n",
      "’----->PUNCT\n",
      "and----->CCONJ\n",
      "live----->VERB\n",
      "in----->ADP\n",
      "grasslands----->NOUN\n",
      "and----->CCONJ\n",
      "open----->ADJ\n",
      "woodlands----->NOUN\n",
      ".----->PUNCT\n",
      "A----->DET\n",
      "pride----->NOUN\n",
      "usually----->ADV\n",
      "comprises----->VERB\n",
      "five----->NUM\n",
      "to----->PART\n",
      "thirty----->NUM\n",
      "lions----->NOUN\n",
      ".----->PUNCT\n",
      "The----->DET\n",
      "pride----->NOUN\n",
      "comprises----->VERB\n",
      "a----->DET\n",
      "few----->ADJ\n",
      "male----->ADJ\n",
      "lions----->NOUN\n",
      ",----->PUNCT\n",
      "and----->CCONJ\n",
      "the----->DET\n",
      "rest----->NOUN\n",
      "are----->AUX\n",
      "lionesses----->NOUN\n",
      "and----->CCONJ\n",
      "their----->PRON\n",
      "cubs----->NOUN\n",
      ".----->PUNCT\n",
      "Lions----->NOUN\n",
      "are----->AUX\n",
      "very----->ADV\n",
      "protective----->ADJ\n",
      "when----->SCONJ\n",
      "it----->PRON\n",
      "comes----->VERB\n",
      "to----->ADP\n",
      "their----->PRON\n",
      "family----->NOUN\n",
      ",----->PUNCT\n",
      "their----->PRON\n",
      "cubs----->NOUN\n",
      ",----->PUNCT\n",
      "and----->CCONJ\n",
      "their----->PRON\n",
      "places----->NOUN\n",
      "of----->ADP\n",
      "survival----->NOUN\n",
      ".----->PUNCT\n",
      "They----->PRON\n",
      "can----->AUX\n",
      "fight----->VERB\n",
      "for----->ADP\n",
      "their----->PRON\n",
      "survival----->NOUN\n",
      "as----->ADV\n",
      "well----->ADV\n",
      "as----->ADP\n",
      "for----->ADP\n",
      "their----->PRON\n",
      "cubs----->NOUN\n",
      ".----->PUNCT\n",
      "Lions----->NOUN\n",
      "hunt----->VERB\n",
      "together----->ADV\n",
      "and----->CCONJ\n",
      "live----->VERB\n",
      "together----->ADV\n",
      "and----->CCONJ\n",
      "sleep----->VERB\n",
      "for----->ADP\n",
      "more----->ADJ\n",
      "than----->ADP\n",
      "20----->NUM\n",
      "hours----->NOUN\n",
      ".----->PUNCT\n",
      "Lions----->NOUN\n",
      "are----->AUX\n",
      "found----->VERB\n",
      "in----->ADP\n",
      "India----->PROPN\n",
      "’s----->PART\n",
      "Gir----->PROPN\n",
      "Forest----->PROPN\n",
      ",----->PUNCT\n",
      "and----->CCONJ\n",
      "India----->PROPN\n",
      "is----->AUX\n",
      "famed----->VERB\n",
      "for----->ADP\n",
      "being----->AUX\n",
      "the----->DET\n",
      "home----->NOUN\n",
      "of----->ADP\n",
      "these----->DET\n",
      "animals----->NOUN\n",
      ".----->PUNCT\n",
      "They----->PRON\n",
      "can----->AUX\n",
      "also----->ADV\n",
      "be----->AUX\n",
      "found----->VERB\n",
      "in----->ADP\n",
      "Eastern----->PROPN\n",
      "Africa----->PROPN\n",
      ",----->PUNCT\n",
      "Southern----->PROPN\n",
      "Africa----->PROPN\n",
      ",----->PUNCT\n",
      "and----->CCONJ\n",
      "other----->ADJ\n",
      "parts----->NOUN\n",
      "of----->ADP\n",
      "Africa----->PROPN\n",
      ".----->PUNCT\n"
     ]
    }
   ],
   "source": [
    "for word in d2:\n",
    "    print(f\"{word.text}----->{word.pos_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0137abd1",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - '/Users/gaurivijaykar/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.11/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.11/share/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.11/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/nltk/corpus/util.py:84\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m     root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mzip_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords.zip/stopwords/\u001b[0m\n\n  Searched in:\n    - '/Users/gaurivijaykar/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.11/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.11/share/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.11/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m stop_list\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m d1:\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m d1\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mstopwords\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwords\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      4\u001b[0m         stop_list\u001b[38;5;241m.\u001b[39mappend(d1\u001b[38;5;241m.\u001b[39mtext)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/nltk/corpus/util.py:121\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLazyCorpusLoader object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/nltk/corpus/util.py:86\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m             root \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Load the corpus.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__reader_cls(root, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/nltk/corpus/util.py:81\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m         root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - '/Users/gaurivijaykar/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.11/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.11/share/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.11/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "stop_list=[]\n",
    "for data in d1:\n",
    "    if d1.text not in stopwords.words(\"english\"):\n",
    "        stop_list.append(d1.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d7f1ad6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m stem_word\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m words \u001b[38;5;129;01min\u001b[39;00m d1:\n\u001b[0;32m----> 4\u001b[0m     stem_word\u001b[38;5;241m.\u001b[39mappend(\u001b[43mps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/nltk/stem/porter.py:658\u001b[0m, in \u001b[0;36mPorterStemmer.stem\u001b[0;34m(self, word, to_lowercase)\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstem\u001b[39m(\u001b[38;5;28mself\u001b[39m, word, to_lowercase\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    655\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;124;03m    :param to_lowercase: if `to_lowercase=True` the word always lowercase\u001b[39;00m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 658\u001b[0m     stem \u001b[38;5;241m=\u001b[39m \u001b[43mword\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m to_lowercase \u001b[38;5;28;01melse\u001b[39;00m word\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNLTK_EXTENSIONS \u001b[38;5;129;01mand\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool:\n\u001b[1;32m    661\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool[stem]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "ps=PorterStemmer()\n",
    "stem_word=[]\n",
    "for words in d1:\n",
    "    stem_word.append(ps.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a1a0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf=[]\n",
    "corpus=[lem1,lem2]\n",
    "for data in corpus:\n",
    "    count={}\n",
    "    for word in data:\n",
    "        if word in count:\n",
    "            count[word]+=1\n",
    "        count[word]=1\n",
    "    tf.append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be6c4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(corpus)):\n",
    "    length=len(corpus[i])\n",
    "    for word in tf[i].keys():\n",
    "        tf[i][word]=tf[i][word]/length"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
